import json
import re  # ğŸ’¡ [ìˆ˜ì •] ì •ê·œí‘œí˜„ì‹ import
from pydantic import ValidationError
from typing import List, Optional
from typing import Dict
import datetime

# ì‹œìŠ¤í…œì˜ ë‹¤ë¥¸ ëª¨ë“ˆë“¤ì„ import í•©ë‹ˆë‹¤.
from .base_agent import BaseAgent
from maestro.core.data_models import (
    ExpertReviewReport,
    IntegratedExecutionPlan,
    InstructionStep,
)
from maestro.utils.llm_handler import call_llm
from maestro.utils.file_io import read_text_file


class ArchitectAgent(BaseAgent):
    """
    ì—¬ëŸ¬ ì „ë¬¸ê°€ì˜ ë¦¬ë·° ë¦¬í¬íŠ¸ë¥¼ ì¢…í•©í•˜ì—¬, NFR ìƒì¶© ê´€ê³„ë¥¼ í•´ê²°í•˜ê³ 
    ìµœì¢… 'í†µí•© ì‹¤í–‰ ê³„íš'ì„ ìˆ˜ë¦½í•˜ëŠ” ì˜ì‚¬ê²°ì • ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
    """

    def _extract_json_from_response(self, response_str: str) -> str:
        """
        LLM ì‘ë‹µì—ì„œ Markdown JSON ì½”ë“œ ë¸”ë¡ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        (```json ... ```) ë˜ëŠ” (``` ... ```) ë˜ëŠ” (raw JSON)ì„ ëª¨ë‘ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        """
        response_str = response_str.strip()
        
        # 1. (```json ... ```) ë˜ëŠ” (``` ... ```) ë¸”ë¡ ì°¾ê¸°
        # ğŸ’¡ [ìˆ˜ì •]: 'json' íƒœê·¸ê°€ ì—†ì–´ë„ ë˜ë„ë¡ (json)? ì‚¬ìš©
        match = re.search(r"```(json)?\s*\n(.*?)\n\s*```", response_str, re.DOTALL)
        if match:
            return match.group(2).strip() # group(2)ê°€ JSON ë‚´ìš©

        # 2. ë¸”ë¡ì´ ì—†ìœ¼ë©´, ì›ë³¸ ë¬¸ìì—´ ìì²´ê°€ ìœ íš¨í•œ JSONì¼ ìˆ˜ ìˆë‹¤ê³  ê°€ì •
        # (e.g., "[]" ë˜ëŠ” "..." ë˜ëŠ” "ì¼ë°˜ í…ìŠ¤íŠ¸")
        return response_str

    def run(
        self,
        v_gen: str,
        expert_reports: List[ExpertReviewReport],
        unit_test_suite: str,
        synthesis_goal: str = "Balance",
        architect_mode: str = "CoT",  # ì•„í‚¤í…íŠ¸ ëª¨ë“œ ì¸ì ì¶”ê°€ (ê¸°ë³¸ê°’ CoT)
        failure_feedback: Optional[str] = None,  # ìê¸° íšŒê³ ë¥¼ ìœ„í•œ ì¸ì
        previous_plan: Optional[
            IntegratedExecutionPlan
        ] = None,  # ìê¸° íšŒê³ ë¥¼ ìœ„í•œ ì¸ì
    ) -> Optional[IntegratedExecutionPlan]:
        """
        ì•„í‚¤í…íŠ¸ ì—ì´ì „íŠ¸ì˜ ë©”ì¸ ì‹¤í–‰ ë¡œì§ì…ë‹ˆë‹¤.
        """
        print("ì•„í‚¤í…íŠ¸ ì—ì´ì „íŠ¸ ì‹¤í–‰...")

        # --- architect_modeì— ë”°ë¼ ë¡œì§ ë¶„ê¸° ---
        if architect_mode == "RuleBased":
            # ê·œì¹™ ê¸°ë°˜ ëª¨ë“œ ì‹¤í–‰
            return self._run_rule_based(
                v_gen, expert_reports, unit_test_suite, synthesis_goal
            )
        else:
            # CoT ê¸°ë°˜ ëª¨ë“œ ì‹¤í–‰ (ê¸°ë³¸ê°’)
            return self._run_cot_based(
                v_gen,
                expert_reports,
                unit_test_suite,
                synthesis_goal,
                failure_feedback,
                previous_plan,
            )
        # ------------------------------------------------

    # --- ê·œì¹™ ê¸°ë°˜ ì‹¤í–‰ ë©”ì†Œë“œ ---
    def _run_rule_based(
        self,
        v_gen: str,
        expert_reports: List[ExpertReviewReport],
        unit_test_suite: str, 
        synthesis_goal: str,
    ) -> Optional[IntegratedExecutionPlan]:
        """
        ê°„ë‹¨í•œ ê·œì¹™(Severity ìš°ì„ )ì— ë”°ë¼ í†µí•© ì‹¤í–‰ ê³„íšì„ ìƒì„±í•©ë‹ˆë‹¤.
        """
        print("ê·œì¹™ ê¸°ë°˜ ì•„í‚¤í…íŠ¸ ë¡œì§ ì‹¤í–‰ ì¤‘...")
        instructions: List[InstructionStep] = []
        step_counter = 1
        processed_suggestion_ids = set()  # ì²˜ë¦¬ëœ ì œì•ˆ ID ì¶”ì 

        # Severityë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ëŠ” ë§µ (ë†’ì„ìˆ˜ë¡ ìš°ì„ )
        severity_map = {"Critical": 4, "High": 3, "Medium": 2, "Low": 1}

        # 1. Critical ë³´ì•ˆ ì œì•ˆ ìµœìš°ì„  ì²˜ë¦¬
        critical_security_reports = [
            r
            for r in expert_reports
            if r.agent_role == "SecurityExpert" and r.severity == "Critical"
        ]
        for report in sorted(critical_security_reports, key=lambda r: r.suggestion_id):
            if report.suggestion_id not in processed_suggestion_ids:
                instructions.append(
                    InstructionStep(
                        step=step_counter,
                        description=f"[ê·œì¹™ ê¸°ë°˜] {report.suggestion_id}: {report.title}",
                        action="REPLACE",  # ë‹¨ìˆœí™”
                        target_code_block=report.target_code_block,
                        new_code=report.proposed_change,  # ì „ë¬¸ê°€ê°€ ì œì•ˆí•œ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        source_suggestion_ids=[report.suggestion_id],
                        rationale="Rule-based: Critical security issue prioritized.",
                    )
                )
                processed_suggestion_ids.add(report.suggestion_id)
                step_counter += 1

        # 2. ë‚˜ë¨¸ì§€ ì œì•ˆ ì¤‘ ë™ì¼ ë¸”ë¡ ê²½í•© ì²˜ë¦¬: Severityê°€ ê°€ì¥ ë†’ì€ ì œì•ˆ ì„ íƒ
        remaining_reports = [
            r for r in expert_reports if r.suggestion_id not in processed_suggestion_ids
        ]
        grouped_reports: Dict[str, List[ExpertReviewReport]] = {}
        for report in remaining_reports:
            if report.target_code_block:
                if report.target_code_block not in grouped_reports:
                    grouped_reports[report.target_code_block] = []
                grouped_reports[report.target_code_block].append(report)

        selected_reports_after_conflict: List[ExpertReviewReport] = []
        for block, reports_in_group in grouped_reports.items():
            best_report = max(
                reports_in_group,
                key=lambda r: (
                    severity_map.get(r.severity, 0),
                    -ord(r.suggestion_id[0]),
                    r.suggestion_id,
                ),
            )
            selected_reports_after_conflict.append(best_report)

        # 3. ì„ íƒëœ ì œì•ˆë“¤ì„ Severity ë‚´ë¦¼ì°¨ìˆœ, ID ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬
        final_selected_reports = sorted(
            selected_reports_after_conflict,
            key=lambda r: (severity_map.get(r.severity, 0), r.suggestion_id),
            reverse=True,  # Severity ë†’ì€ ìˆœì„œëŒ€ë¡œ
        )
        for report in final_selected_reports:
            if report.suggestion_id not in processed_suggestion_ids:
                instructions.append(
                    InstructionStep(
                        step=step_counter,
                        description=f"[ê·œì¹™ ê¸°ë°˜] {report.suggestion_id}: {report.title}",
                        action="REPLACE",  # ë‹¨ìˆœí™”
                        target_code_block=report.target_code_block,
                        new_code=report.proposed_change,
                        source_suggestion_ids=[report.suggestion_id],
                        rationale=f"Rule-based: Highest severity ({report.severity}) suggestion selected for block {report.target_code_block}.",
                    )
                )
                processed_suggestion_ids.add(report.suggestion_id)
                step_counter += 1

        if not instructions:
            print("ê·œì¹™ ê¸°ë°˜ ì•„í‚¤í…íŠ¸: ì ìš©í•  ìœ íš¨í•œ ê°œì„ ì•ˆì´ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # ìµœì¢… ê³„íš ìƒì„±
        plan = IntegratedExecutionPlan(
            work_order_id=f"WO-RuleBased-{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}",
            synthesis_goal=synthesis_goal,
            instructions=instructions,
        )
        print(f"ê·œì¹™ ê¸°ë°˜ í†µí•© ì‹¤í–‰ ê³„íš ìƒì„± ì™„ë£Œ: {len(instructions)}ê°œ ì‘ì—…")
        return plan

    def _run_cot_based(
        self,
        v_gen: str,
        expert_reports: List[ExpertReviewReport],
        unit_test_suite: str,
        synthesis_goal: str = "Balance",
        failure_feedback: Optional[str] = None, 
        previous_plan: Optional[IntegratedExecutionPlan] = None,
    ) -> Optional[IntegratedExecutionPlan]:
        """
        CoT ì¶”ë¡ ì„ ì‚¬ìš©í•˜ì—¬ í†µí•© ì‹¤í–‰ ê³„íšì„ ìƒì„±í•©ë‹ˆë‹¤.
        """
        print("CoT ê¸°ë°˜ ì•„í‚¤í…íŠ¸ ë¡œì§ ì‹¤í–‰ ì¤‘...")
        # 1. í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        prompt_path = (
            self.config["paths"]["prompt_template_dir"] + "architect_prompt.md"
        )
        try:
            prompt_template = read_text_file(prompt_path)
        except FileNotFoundError:
            print(f"ì˜¤ë¥˜: ì•„í‚¤í…íŠ¸ í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {prompt_path}")
            return None

        reports_json_str = json.dumps(
            [report.model_dump() for report in expert_reports],
            indent=2,
            ensure_ascii=False,
        )

        feedback_section = ""
        if failure_feedback:
            feedback_section += f"\n\n# PREVIOUS ATTEMPT FEEDBACK\n{failure_feedback}"

        # ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±
        try:
            prompt = prompt_template.format(
                v_gen=v_gen,
                expert_reports=reports_json_str,
                unit_test_suite=unit_test_suite,
                synthesis_goal=synthesis_goal,
                failure_feedback_section=feedback_section,  # í”¼ë“œë°± ì„¹ì…˜ ì‚½ì…
            )
        except KeyError as e:
            print(f"ì˜¤ë¥˜: ì•„í‚¤í…íŠ¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í¬ë§·íŒ… ì‹¤íŒ¨. ëˆ„ë½ëœ í‚¤: {e}")
            print(
                "í…œí”Œë¦¿ì— {v_gen}, {expert_reports}, {unit_test_suite}, {failure_feedback_section} ë“±ì´ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
            )
            return None

        messages = [
            {
                "role": "system",
                "content": "You are a world-class AI Software Architect, skilled in resolving conflicts and creating strategic refactoring plans using Chain of Thought reasoning.",
            },
            {"role": "user", "content": prompt},
        ]

        # 2. LLM í˜¸ì¶œ
        try:
            response_str = call_llm(messages, self.config["llm"])
            print("LLMìœ¼ë¡œë¶€í„° í†µí•© ì‹¤í–‰ ê³„íš ì´ˆì•ˆì„ ìˆ˜ì‹ í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"LLM API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None

        # 3. ê²°ê³¼ íŒŒì‹± ë° ë°ì´í„° ëª¨ë¸ ê²€ì¦
        try:
            json_str = self._extract_json_from_response(response_str)

            # ğŸ’¡ [BUG FIX]: ë¹ˆ ë¬¸ìì—´ ë˜ëŠ” í…ìŠ¤íŠ¸ ì‘ë‹µ ë°©ì–´
            if not json_str:
                print(f"LLM ì‘ë‹µ ê²€ì¦ ì‹¤íŒ¨: ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                print(f"LLM ì›ë³¸ ì‘ë‹µ:\n---\n{response_str}\n---")
                return None
            
            parsed_data = json.loads(json_str)
            validated_plan = IntegratedExecutionPlan.model_validate(parsed_data)

            print(
                f"í†µí•© ì‹¤í–‰ ê³„íš ê²€ì¦ ì™„ë£Œ: Work Order ID '{validated_plan.work_order_id}'"
            )
            return validated_plan
        except (json.JSONDecodeError, ValidationError) as e:
            print(f"LLM ì‘ë‹µ ê²€ì¦ ì‹¤íŒ¨: {e}")
            print(
                f"LLM ì›ë³¸ ì‘ë‹µ (ê¸¸ì´: {len(response_str)}):\n---\n{response_str[:1000]}{'...' if len(response_str) > 1000 else ''}\n---"
            )
            return None