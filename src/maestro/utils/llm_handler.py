import os
import json
from typing import List, Dict, Any, Optional

# --- ëª¨ë“ˆ ë ˆë²¨ ë³€ìˆ˜ ---
_llm_provider: Optional[str] = None
_api_key: Optional[str] = None
_client = None
_mock_call_counter: int = 0 # <-- í˜¸ì¶œ ì¹´ìš´í„°


def set_llm_provider(config: Dict[str, Any]):
    """
    main_controllerì—ì„œ í˜¸ì¶œë˜ì–´, ì‚¬ìš©í•  LLM ê³µê¸‰ìì™€ API í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    """
    global _llm_provider, _api_key, _client, _mock_call_counter
    _mock_call_counter = 0 # <-- ğŸ’¡ ì¤‘ìš”: ì»¨íŠ¸ë¡¤ëŸ¬ê°€ ì´ˆê¸°í™”ë  ë•Œë§ˆë‹¤ ì¹´ìš´í„° ë¦¬ì…‹

    provider = config.get("provider")
    if not provider:
        raise ValueError(
            "LLM ì„¤ì •(config.yml)ì— 'provider'ê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        )

    _llm_provider = provider

    if _llm_provider == "openai":
        try:
            from openai import OpenAI
        except ImportError:
            raise ImportError(
                "OpenAIë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install openai'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”."
            )
        _api_key = os.getenv("OPENAI_API_KEY")
        if not _api_key:
            raise ValueError("'OPENAI_API_KEY' í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        _client = OpenAI(api_key=_api_key)
        print("LLM ê³µê¸‰ìê°€ 'openai'ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")

    elif _llm_provider == "anthropic":
        # (Anthropic ë¡œì§ ... ìƒëµ)
        pass

    elif _llm_provider == "mock":
        _client = "mock"
        print(
            "LLM ê³µê¸‰ìê°€ 'mock'ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤ì œ API í˜¸ì¶œì€ ì´ë£¨ì–´ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤."
        )
    else:
        raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” LLM ê³µê¸‰ìì…ë‹ˆë‹¤: {_llm_provider}")


def call_llm(messages: List[Dict[str, str]], llm_config: Dict[str, Any]) -> str:
    """
    ì„¤ì •ëœ LLM ê³µê¸‰ìë¥¼ ì‚¬ìš©í•˜ì—¬ APIë¥¼ í˜¸ì¶œí•˜ê³  ì‘ë‹µì„ ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if _client is None:
        set_llm_provider(llm_config)

    print(f"'{_llm_provider}' APIì— ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤...")

    try:
        if _llm_provider == "openai":
            # (OpenAI ë¡œì§ ... ìƒëµ)
            model = llm_config.get("model", "gpt-5")
            response = _client.chat.completions.create(model=model, messages=messages)
            return response.choices[0].message.content or ""
        
        elif _llm_provider == "anthropic":
            # (Anthropic ë¡œì§ ... ìƒëµ)
            pass

        # --- ğŸ‘‡ "ì¹´ìš´í„° ê¸°ë°˜" Mock ë¡œì§ ì‹œì‘ ğŸ‘‡ ---
        elif _llm_provider == "mock":
            global _mock_call_counter
            _mock_call_counter += 1

            # --- ğŸ’¡ 1, 2, 3ë²ˆì§¸ í˜¸ì¶œì€ "ì „ë¬¸ê°€" ---
            if _mock_call_counter <= 3:
                # 1ë‹¨ê³„ ì „ë¬¸ê°€ìš© 'ë³´ê³ ì„œ(list)' ë°˜í™˜
                mock_role = "MockExpert"
                if _mock_call_counter == 1:
                    mock_role = "PerformanceExpert"
                elif _mock_call_counter == 2:
                    mock_role = "ReadabilityExpert"
                else:
                    mock_role = "SecurityExpert"
                
                fake_report = [
                    {
                        "suggestion_id": f"MOCK-00{_mock_call_counter}",
                        "agent_role": mock_role, 
                        "title": f"Mock suggestion from {mock_role}",
                        "target_code_block": "main.py#L1-L1",
                        "severity": "Low",
                        "reasoning": "This is a mock response for an Expert.",
                        "proposed_change": "pass",
                        "expected_impact": "None. This is a mock.",
                        "potential_tradeoffs": "None."
                    }
                ]
                return json.dumps(fake_report)

            # --- ğŸ’¡ 4ë²ˆì§¸ í˜¸ì¶œì€ "ì•„í‚¤í…íŠ¸" ---
            elif _mock_call_counter == 4:
                # 2ë‹¨ê³„ ì•„í‚¤í…íŠ¸ìš© 'ê³„íšì„œ(dict)' ë°˜í™˜
                fake_plan = {
                    "work_order_id": "MOCK-WO-001", 
                    "synthesis_goal": "Balance",      
                    "reasoning_log": "This is a mock reasoning log to pass validation.",
                    "instructions": [                 
                        {
                            "step": 1,
                            "action": "REPLACE", 
                            "description": "Mock step 1: Extract function (to pass validation).",
                            "target_code_block": "main.py#L1-L1",
                            "details": {
                                "refactor_type": "EXTRACT_FUNCTION", 
                                "new_function_name": "mock_extracted_function",
                                "new_function_body": "def mock_extracted_function():\n    pass # Mock body"
                            },
                            "source_suggestion_ids": ["MOCK-001", "MOCK-002", "MOCK-003"],
                            "rationale": "Mock rationale based on principles."
                        }
                    ]
                }
                return json.dumps(fake_plan)
            
            # --- ğŸ’¡ 5ë²ˆì§¸ í˜¸ì¶œì€ "ê°œë°œì" ---
            elif _mock_call_counter == 5:
                # ğŸ’¡ğŸ’¡ğŸ’¡ [ìˆ˜ì •] 01:30 ë¡œê·¸ì˜ 2ê°œ ì—ëŸ¬ë¥¼ ì¡ê¸° ìœ„í•´ ì—…ê·¸ë ˆì´ë“œ! ğŸ’¡ğŸ’¡ğŸ’¡
                fake_dev_output = {
                    "status": "SUCCESS", # <-- [ìˆ˜ì •] "MOCK_SUCCESS" -> "SUCCESS"
                    "final_code": "# This is mock code from the developer",
                    "log": ["Mock Developer Agent ran successfully."] # <-- [ìˆ˜ì •] str -> list
                }
                return json.dumps(fake_dev_output)

            # --- ğŸ’¡ ê·¸ ì™¸ (ìê¸° íšŒê³  ë“±) ---
            else:
                return '{"status": "mock_fallback_loop", "log": "Mock loop detected."}'
        # --- ğŸ‘† Mock ë¡œì§ ë ğŸ‘† ---

        return ""

    except Exception as e:
        print(f"LLM API í˜¸ì¶œ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise